{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "files = glob.glob('profiles/*.pkl')\n",
    "\n",
    "profiles_train = {}\n",
    "profiles_val = {}\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    with open(file, 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "\n",
    "        if i in [2, 3, 4, 5, 6, 7]:\n",
    "            profiles_train = {**profiles_train, **tmp}\n",
    "\n",
    "        else:\n",
    "            profiles_val = {**profiles_val, **tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    }
   ],
   "source": [
    "X_train = {key: ut.profile_to_df(value) for key, value in profiles_train.items() if 'layer' in value.keys()}\n",
    "X_val = {key: ut.profile_to_df(value) for key, value in profiles_val.items() if 'layer' in value.keys()}\n",
    "\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple train/val/test data set where we will gather profiles from similar surveys in a training/validation manner while omitting some surveys completely. Let's import some dummy functions made by ChatGPT to build a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        self.data = data_dict\n",
    "        self.le = LabelEncoder().fit(['B', 'S', 'WL']) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get profile key\n",
    "        key = list(self.data.keys())[idx]\n",
    "        features, labels = self.data[key]\n",
    "\n",
    "        # Convert to tensors\n",
    "        features = torch.tensor(features.values, dtype=torch.float32)  # Shape: (seq_len, num_features)\n",
    "        labels = torch.tensor(self.le.transform(labels), dtype=torch.long)     # Shape: (seq_len,)\n",
    "\n",
    "        return {\n",
    "            \"input_features\": features,\n",
    "            \"labels\": labels,\n",
    "            \"attention_mask\": torch.ones(features.shape[0], dtype=torch.long)  # No padding yet\n",
    "        }\n",
    "    \n",
    "train_dataset = SignalDataset(X_train)\n",
    "val_dataset = SignalDataset(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_features = [item[\"input_features\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    attention_masks = [item[\"attention_mask\"] for item in batch]\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    input_features = pad_sequence(input_features, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)  # Use -100 for ignored labels\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        \"input_features\": input_features,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_masks\n",
    "    }\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, rnn_size=256, dropout=0.2, dense_units=0):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_shape[1]  # Number of features\n",
    "        self.output_size = output_shape  # Number of output labels\n",
    "        self.rnn_size = rnn_size  # LSTM hidden units\n",
    "        self.dropout = dropout  # Dropout rate\n",
    "        \n",
    "        # Encoder (LSTM or Bidirectional LSTM)\n",
    "        self.encoder_lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.rnn_size, num_layers=1, \n",
    "                                        bidirectional=True, dropout=self.dropout, batch_first=True)\n",
    "\n",
    "\n",
    "        self.attention_layer = nn.MultiheadAttention(embed_dim=rnn_size * 2, num_heads=1, dropout=self.dropout)\n",
    "        \n",
    "        # Decoder LSTM\n",
    "        self.decoder_lstm = nn.LSTM(input_size=rnn_size * 2, hidden_size=rnn_size, num_layers=1, dropout=self.dropout, batch_first=True)\n",
    "        \n",
    "        # Output layer (Dense)\n",
    "        self.output_layer = nn.Linear(rnn_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        encoder_output, (h, c) = self.encoder_lstm(x)\n",
    "        \n",
    "        # The input to attention layer must be in (seq_len, batch, embed_dim) format\n",
    "        encoder_output = encoder_output.permute(1, 0, 2)\n",
    "        attn_output, _ = self.attention_layer(encoder_output, encoder_output, encoder_output)\n",
    "        attn_output = attn_output.permute(1, 0, 2)\n",
    "\n",
    "        # Decoder (Repeat context vector or use attention)\n",
    "        decoder_input = attn_output  # In a typical Seq2Seq, we'd use the previous output as input, here we just pass the context vector\n",
    "        decoder_output, (h, c) = self.decoder_lstm(decoder_input)\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.output_layer(decoder_output)\n",
    "        output = torch.softmax(output, dim=-1)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Epoch 0:  30%|███       | 21/69 [01:18<03:36,  4.50s/it, loss=0.881]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Initialize Model, Loss, Optimizer\n",
    "num_channels = 11  # Number of features in your signal (channels)\n",
    "num_classes = 3    # Number of classes for segmentation\n",
    "model = EncoderDecoder((None, num_channels), num_classes)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)  # Ignore padded labels\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "loss_curve = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        input_features = batch[\"input_features\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_features)\n",
    "        loss = loss_fn(outputs.view(-1, num_classes), labels.view(-1))\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        loss_curve.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, features=(64, 128, 256, 512)):\n",
    "        super(UNet1D, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "        # Encoder: Down-sampling\n",
    "        for feature in features:\n",
    "            self.encoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(input_channels, feature, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv1d(feature, feature, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                )\n",
    "            )\n",
    "            input_channels = feature\n",
    "\n",
    "        # Decoder: Up-sampling\n",
    "        for feature in reversed(features):\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(2 * feature, feature, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv1d(feature, feature, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.upsample = nn.ConvTranspose1d(feature, feature // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        # Final output layer\n",
    "        self.final_layer = nn.Conv1d(features[0], output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Decoder\n",
    "        for idx, layer in enumerate(self.decoder):\n",
    "            x = self.upsample(x)\n",
    "            if x.size(-1) != skip_connections[idx].size(-1):\n",
    "                x = F.pad(x, (0, skip_connections[idx].size(-1) - x.size(-1)))\n",
    "            x = torch.cat((skip_connections[idx], x), dim=1)\n",
    "            x = layer(x)\n",
    "\n",
    "        # Final output\n",
    "        return self.final_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles, labels = np.array(list(X_train.values()), dtype='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6, loss: 0.069\n",
      "epoch 1/1000, average loss: 0.100\n",
      "6/6, loss: 0.086\n",
      "epoch 2/1000, average loss: 0.101\n",
      "6/6, loss: 0.059\n",
      "epoch 3/1000, average loss: 0.097\n",
      "6/6, loss: 0.124\n",
      "epoch 4/1000, average loss: 0.103\n",
      "6/6, loss: 0.066\n",
      "epoch 5/1000, average loss: 0.098\n",
      "6/6, loss: 0.061\n",
      "epoch 6/1000, average loss: 0.096\n",
      "6/6, loss: 0.031\n",
      "epoch 7/1000, average loss: 0.095\n",
      "6/6, loss: 0.152\n",
      "epoch 8/1000, average loss: 0.109\n",
      "6/6, loss: 0.184\n",
      "epoch 9/1000, average loss: 0.111\n",
      "6/6, loss: 0.079\n",
      "epoch 10/1000, average loss: 0.098\n",
      "6/6, loss: 0.149\n",
      "epoch 11/1000, average loss: 0.107\n",
      "6/6, loss: 0.116\n",
      "epoch 12/1000, average loss: 0.102\n",
      "6/6, loss: 0.064\n",
      "epoch 13/1000, average loss: 0.096\n",
      "6/6, loss: 0.105\n",
      "epoch 14/1000, average loss: 0.102\n",
      "6/6, loss: 0.066\n",
      "epoch 15/1000, average loss: 0.097\n",
      "6/6, loss: 0.056\n",
      "epoch 16/1000, average loss: 0.096\n",
      "6/6, loss: 0.105\n",
      "epoch 17/1000, average loss: 0.101\n",
      "6/6, loss: 0.131\n",
      "epoch 18/1000, average loss: 0.104\n",
      "6/6, loss: 0.132\n",
      "epoch 19/1000, average loss: 0.107\n",
      "6/6, loss: 0.072\n",
      "epoch 20/1000, average loss: 0.096\n",
      "6/6, loss: 0.081\n",
      "epoch 21/1000, average loss: 0.099\n",
      "6/6, loss: 0.151\n",
      "epoch 22/1000, average loss: 0.107\n",
      "6/6, loss: 0.087\n",
      "epoch 23/1000, average loss: 0.101\n",
      "6/6, loss: 0.062\n",
      "epoch 24/1000, average loss: 0.096\n",
      "6/6, loss: 0.033\n",
      "epoch 25/1000, average loss: 0.092\n",
      "6/6, loss: 0.105\n",
      "epoch 26/1000, average loss: 0.102\n",
      "6/6, loss: 0.083\n",
      "epoch 27/1000, average loss: 0.102\n",
      "6/6, loss: 0.195\n",
      "epoch 28/1000, average loss: 0.111\n",
      "6/6, loss: 0.131\n",
      "epoch 29/1000, average loss: 0.105\n",
      "6/6, loss: 0.056\n",
      "epoch 30/1000, average loss: 0.096\n",
      "6/6, loss: 0.065\n",
      "epoch 31/1000, average loss: 0.096\n",
      "6/6, loss: 0.057\n",
      "epoch 32/1000, average loss: 0.095\n",
      "6/6, loss: 0.056\n",
      "epoch 33/1000, average loss: 0.096\n",
      "6/6, loss: 0.105\n",
      "epoch 34/1000, average loss: 0.101\n",
      "6/6, loss: 0.097\n",
      "epoch 35/1000, average loss: 0.101\n",
      "6/6, loss: 0.064\n",
      "epoch 36/1000, average loss: 0.096\n",
      "6/6, loss: 0.188\n",
      "epoch 37/1000, average loss: 0.112\n",
      "6/6, loss: 0.056\n",
      "epoch 38/1000, average loss: 0.099\n",
      "6/6, loss: 0.187\n",
      "epoch 39/1000, average loss: 0.113\n",
      "6/6, loss: 0.089\n",
      "epoch 40/1000, average loss: 0.099\n",
      "6/6, loss: 0.146\n",
      "epoch 41/1000, average loss: 0.108\n",
      "6/6, loss: 0.177\n",
      "epoch 42/1000, average loss: 0.111\n",
      "6/6, loss: 0.099\n",
      "epoch 43/1000, average loss: 0.100\n",
      "6/6, loss: 0.105\n",
      "epoch 44/1000, average loss: 0.102\n",
      "6/6, loss: 0.116\n",
      "epoch 45/1000, average loss: 0.102\n",
      "6/6, loss: 0.138\n",
      "epoch 46/1000, average loss: 0.107\n",
      "6/6, loss: 0.141\n",
      "epoch 47/1000, average loss: 0.105\n",
      "6/6, loss: 0.067\n",
      "epoch 48/1000, average loss: 0.095\n",
      "6/6, loss: 0.140\n",
      "epoch 49/1000, average loss: 0.104\n",
      "6/6, loss: 0.079\n",
      "epoch 50/1000, average loss: 0.098\n",
      "6/6, loss: 0.104\n",
      "epoch 51/1000, average loss: 0.102\n",
      "6/6, loss: 0.064\n",
      "epoch 52/1000, average loss: 0.095\n",
      "6/6, loss: 0.034\n",
      "epoch 53/1000, average loss: 0.092\n",
      "6/6, loss: 0.149\n",
      "epoch 54/1000, average loss: 0.110\n",
      "6/6, loss: 0.080\n",
      "epoch 55/1000, average loss: 0.097\n",
      "6/6, loss: 0.064\n",
      "epoch 56/1000, average loss: 0.096\n",
      "6/6, loss: 0.062\n",
      "epoch 57/1000, average loss: 0.096\n",
      "6/6, loss: 0.147\n",
      "epoch 58/1000, average loss: 0.106\n",
      "6/6, loss: 0.142\n",
      "epoch 59/1000, average loss: 0.105\n",
      "6/6, loss: 0.083\n",
      "epoch 60/1000, average loss: 0.099\n",
      "6/6, loss: 0.198\n",
      "epoch 61/1000, average loss: 0.118\n",
      "6/6, loss: 0.081\n",
      "epoch 62/1000, average loss: 0.103\n",
      "6/6, loss: 0.079\n",
      "epoch 63/1000, average loss: 0.104\n",
      "6/6, loss: 0.068\n",
      "epoch 64/1000, average loss: 0.101\n",
      "6/6, loss: 0.089\n",
      "epoch 65/1000, average loss: 0.104\n",
      "6/6, loss: 0.155\n",
      "epoch 66/1000, average loss: 0.109\n",
      "6/6, loss: 0.081\n",
      "epoch 67/1000, average loss: 0.100\n",
      "6/6, loss: 0.099\n",
      "epoch 68/1000, average loss: 0.101\n",
      "6/6, loss: 0.027\n",
      "epoch 69/1000, average loss: 0.093\n",
      "6/6, loss: 0.117\n",
      "epoch 70/1000, average loss: 0.104\n",
      "6/6, loss: 0.133\n",
      "epoch 71/1000, average loss: 0.106\n",
      "6/6, loss: 0.139\n",
      "epoch 72/1000, average loss: 0.106\n",
      "6/6, loss: 0.180\n",
      "epoch 73/1000, average loss: 0.109\n",
      "6/6, loss: 0.131\n",
      "epoch 74/1000, average loss: 0.106\n",
      "6/6, loss: 0.131\n",
      "epoch 75/1000, average loss: 0.105\n",
      "6/6, loss: 0.137\n",
      "epoch 76/1000, average loss: 0.104\n",
      "6/6, loss: 0.065\n",
      "epoch 77/1000, average loss: 0.096\n",
      "6/6, loss: 0.155\n",
      "epoch 78/1000, average loss: 0.108\n",
      "6/6, loss: 0.103\n",
      "epoch 79/1000, average loss: 0.100\n",
      "6/6, loss: 0.154\n",
      "epoch 80/1000, average loss: 0.107\n",
      "6/6, loss: 0.068\n",
      "epoch 81/1000, average loss: 0.096\n",
      "6/6, loss: 0.027\n",
      "epoch 82/1000, average loss: 0.091\n",
      "6/6, loss: 0.151\n",
      "epoch 83/1000, average loss: 0.108\n",
      "6/6, loss: 0.026\n",
      "epoch 84/1000, average loss: 0.093\n",
      "6/6, loss: 0.060\n",
      "epoch 85/1000, average loss: 0.097\n",
      "6/6, loss: 0.151\n",
      "epoch 86/1000, average loss: 0.108\n",
      "6/6, loss: 0.066\n",
      "epoch 87/1000, average loss: 0.099\n",
      "6/6, loss: 0.116\n",
      "epoch 88/1000, average loss: 0.102\n",
      "6/6, loss: 0.075\n",
      "epoch 89/1000, average loss: 0.099\n",
      "6/6, loss: 0.026\n",
      "epoch 90/1000, average loss: 0.094\n",
      "6/6, loss: 0.057\n",
      "epoch 91/1000, average loss: 0.096\n",
      "6/6, loss: 0.149\n",
      "epoch 92/1000, average loss: 0.107\n",
      "6/6, loss: 0.084\n",
      "epoch 93/1000, average loss: 0.100\n",
      "6/6, loss: 0.081\n",
      "epoch 94/1000, average loss: 0.098\n",
      "6/6, loss: 0.079\n",
      "epoch 95/1000, average loss: 0.097\n",
      "6/6, loss: 0.084\n",
      "epoch 96/1000, average loss: 0.099\n",
      "6/6, loss: 0.141\n",
      "epoch 97/1000, average loss: 0.105\n",
      "6/6, loss: 0.130\n",
      "epoch 98/1000, average loss: 0.106\n",
      "6/6, loss: 0.027\n",
      "epoch 99/1000, average loss: 0.093\n",
      "6/6, loss: 0.143\n",
      "epoch 100/1000, average loss: 0.106\n",
      "6/6, loss: 0.081\n",
      "epoch 101/1000, average loss: 0.097\n",
      "6/6, loss: 0.116\n",
      "epoch 102/1000, average loss: 0.101\n",
      "6/6, loss: 0.180\n",
      "epoch 103/1000, average loss: 0.108\n",
      "6/6, loss: 0.058\n",
      "epoch 104/1000, average loss: 0.096\n",
      "6/6, loss: 0.026\n",
      "epoch 105/1000, average loss: 0.093\n",
      "6/6, loss: 0.103\n",
      "epoch 106/1000, average loss: 0.101\n",
      "6/6, loss: 0.064\n",
      "epoch 107/1000, average loss: 0.097\n",
      "6/6, loss: 0.084\n",
      "epoch 108/1000, average loss: 0.096\n",
      "6/6, loss: 0.149\n",
      "epoch 109/1000, average loss: 0.109\n",
      "6/6, loss: 0.102\n",
      "epoch 110/1000, average loss: 0.101\n",
      "6/6, loss: 0.066\n",
      "epoch 111/1000, average loss: 0.095\n",
      "6/6, loss: 0.150\n",
      "epoch 112/1000, average loss: 0.106\n",
      "6/6, loss: 0.115\n",
      "epoch 113/1000, average loss: 0.101\n",
      "6/6, loss: 0.122\n",
      "epoch 114/1000, average loss: 0.103\n",
      "6/6, loss: 0.085\n",
      "epoch 115/1000, average loss: 0.097\n",
      "6/6, loss: 0.187\n",
      "epoch 116/1000, average loss: 0.109\n",
      "6/6, loss: 0.152\n",
      "epoch 117/1000, average loss: 0.108\n",
      "6/6, loss: 0.064\n",
      "epoch 118/1000, average loss: 0.096\n",
      "6/6, loss: 0.147\n",
      "epoch 119/1000, average loss: 0.105\n",
      "6/6, loss: 0.068\n",
      "epoch 120/1000, average loss: 0.096\n",
      "6/6, loss: 0.104\n",
      "epoch 121/1000, average loss: 0.098\n",
      "6/6, loss: 0.120\n",
      "epoch 122/1000, average loss: 0.103\n",
      "6/6, loss: 0.062\n",
      "epoch 123/1000, average loss: 0.096\n",
      "6/6, loss: 0.099\n",
      "epoch 124/1000, average loss: 0.100\n",
      "6/6, loss: 0.129\n",
      "epoch 125/1000, average loss: 0.104\n",
      "6/6, loss: 0.056\n",
      "epoch 126/1000, average loss: 0.096\n",
      "6/6, loss: 0.184\n",
      "epoch 127/1000, average loss: 0.108\n",
      "6/6, loss: 0.096\n",
      "epoch 128/1000, average loss: 0.099\n",
      "6/6, loss: 0.081\n",
      "epoch 129/1000, average loss: 0.097\n",
      "6/6, loss: 0.103\n",
      "epoch 130/1000, average loss: 0.098\n",
      "6/6, loss: 0.103\n",
      "epoch 131/1000, average loss: 0.102\n",
      "6/6, loss: 0.128\n",
      "epoch 132/1000, average loss: 0.103\n",
      "6/6, loss: 0.148\n",
      "epoch 133/1000, average loss: 0.104\n",
      "6/6, loss: 0.057\n",
      "epoch 134/1000, average loss: 0.091\n",
      "6/6, loss: 0.103\n",
      "epoch 135/1000, average loss: 0.098\n",
      "6/6, loss: 0.060\n",
      "epoch 136/1000, average loss: 0.092\n",
      "6/6, loss: 0.128\n",
      "epoch 137/1000, average loss: 0.103\n",
      "6/6, loss: 0.166\n",
      "epoch 138/1000, average loss: 0.108\n",
      "6/6, loss: 0.105\n",
      "epoch 139/1000, average loss: 0.099\n",
      "6/6, loss: 0.177\n",
      "epoch 140/1000, average loss: 0.107\n",
      "6/6, loss: 0.143\n",
      "epoch 141/1000, average loss: 0.103\n",
      "6/6, loss: 0.103\n",
      "epoch 142/1000, average loss: 0.098\n",
      "6/6, loss: 0.102\n",
      "epoch 143/1000, average loss: 0.100\n",
      "6/6, loss: 0.145\n",
      "epoch 144/1000, average loss: 0.111\n",
      "6/6, loss: 0.120\n",
      "epoch 145/1000, average loss: 0.103\n",
      "6/6, loss: 0.137\n",
      "epoch 146/1000, average loss: 0.106\n",
      "6/6, loss: 0.064\n",
      "epoch 147/1000, average loss: 0.102\n",
      "6/6, loss: 0.140\n",
      "epoch 148/1000, average loss: 0.114\n",
      "6/6, loss: 0.151\n",
      "epoch 149/1000, average loss: 0.112\n",
      "6/6, loss: 0.108\n",
      "epoch 150/1000, average loss: 0.106\n",
      "6/6, loss: 0.136\n",
      "epoch 151/1000, average loss: 0.110\n",
      "6/6, loss: 0.119\n",
      "epoch 152/1000, average loss: 0.108\n",
      "6/6, loss: 0.149\n",
      "epoch 153/1000, average loss: 0.110\n",
      "6/6, loss: 0.084\n",
      "epoch 154/1000, average loss: 0.106\n",
      "6/6, loss: 0.130\n",
      "epoch 155/1000, average loss: 0.111\n",
      "6/6, loss: 0.036\n",
      "epoch 156/1000, average loss: 0.099\n",
      "6/6, loss: 0.061\n",
      "epoch 157/1000, average loss: 0.102\n",
      "6/6, loss: 0.125\n",
      "epoch 158/1000, average loss: 0.109\n",
      "6/6, loss: 0.077\n",
      "epoch 159/1000, average loss: 0.104\n",
      "6/6, loss: 0.123\n",
      "epoch 160/1000, average loss: 0.107\n",
      "6/6, loss: 0.138\n",
      "epoch 161/1000, average loss: 0.109\n",
      "6/6, loss: 0.134\n",
      "epoch 162/1000, average loss: 0.108\n",
      "6/6, loss: 0.069\n",
      "epoch 163/1000, average loss: 0.101\n",
      "6/6, loss: 0.151\n",
      "epoch 164/1000, average loss: 0.114\n",
      "6/6, loss: 0.063\n",
      "epoch 165/1000, average loss: 0.096\n",
      "6/6, loss: 0.140\n",
      "epoch 166/1000, average loss: 0.109\n",
      "6/6, loss: 0.120\n",
      "epoch 167/1000, average loss: 0.105\n",
      "6/6, loss: 0.081\n",
      "epoch 168/1000, average loss: 0.101\n",
      "6/6, loss: 0.104\n",
      "epoch 169/1000, average loss: 0.102\n",
      "6/6, loss: 0.067\n",
      "epoch 170/1000, average loss: 0.098\n",
      "6/6, loss: 0.135\n",
      "epoch 171/1000, average loss: 0.106\n",
      "6/6, loss: 0.108\n",
      "epoch 172/1000, average loss: 0.101\n",
      "6/6, loss: 0.131\n",
      "epoch 173/1000, average loss: 0.106\n",
      "6/6, loss: 0.068\n",
      "epoch 174/1000, average loss: 0.097\n",
      "6/6, loss: 0.181\n",
      "epoch 175/1000, average loss: 0.113\n",
      "6/6, loss: 0.066\n",
      "epoch 176/1000, average loss: 0.097\n",
      "6/6, loss: 0.079\n",
      "epoch 177/1000, average loss: 0.099\n",
      "6/6, loss: 0.105\n",
      "epoch 178/1000, average loss: 0.103\n",
      "6/6, loss: 0.065\n",
      "epoch 179/1000, average loss: 0.097\n",
      "6/6, loss: 0.059\n",
      "epoch 180/1000, average loss: 0.098\n",
      "6/6, loss: 0.064\n",
      "epoch 181/1000, average loss: 0.096\n",
      "6/6, loss: 0.120\n",
      "epoch 182/1000, average loss: 0.104\n",
      "6/6, loss: 0.186\n",
      "epoch 183/1000, average loss: 0.109\n",
      "6/6, loss: 0.119\n",
      "epoch 184/1000, average loss: 0.103\n",
      "6/6, loss: 0.185\n",
      "epoch 185/1000, average loss: 0.111\n",
      "6/6, loss: 0.182\n",
      "epoch 186/1000, average loss: 0.111\n",
      "6/6, loss: 0.058\n",
      "epoch 187/1000, average loss: 0.097\n",
      "6/6, loss: 0.149\n",
      "epoch 188/1000, average loss: 0.109\n",
      "6/6, loss: 0.105\n",
      "epoch 189/1000, average loss: 0.101\n",
      "6/6, loss: 0.175\n",
      "epoch 190/1000, average loss: 0.110\n",
      "6/6, loss: 0.181\n",
      "epoch 191/1000, average loss: 0.112\n",
      "6/6, loss: 0.108\n",
      "epoch 192/1000, average loss: 0.104\n",
      "6/6, loss: 0.107\n",
      "epoch 193/1000, average loss: 0.103\n",
      "6/6, loss: 0.184\n",
      "epoch 194/1000, average loss: 0.114\n",
      "6/6, loss: 0.072\n",
      "epoch 195/1000, average loss: 0.098\n",
      "6/6, loss: 0.027\n",
      "epoch 196/1000, average loss: 0.092\n",
      "6/6, loss: 0.086\n",
      "epoch 197/1000, average loss: 0.101\n",
      "6/6, loss: 0.107\n",
      "epoch 198/1000, average loss: 0.103\n",
      "6/6, loss: 0.064\n",
      "epoch 199/1000, average loss: 0.098\n",
      "6/6, loss: 0.062\n",
      "epoch 200/1000, average loss: 0.098\n",
      "6/6, loss: 0.133\n",
      "epoch 201/1000, average loss: 0.106\n",
      "6/6, loss: 0.181\n",
      "epoch 202/1000, average loss: 0.112\n",
      "6/6, loss: 0.176\n",
      "epoch 203/1000, average loss: 0.111\n",
      "6/6, loss: 0.069\n",
      "epoch 204/1000, average loss: 0.096\n",
      "6/6, loss: 0.116\n",
      "epoch 205/1000, average loss: 0.104\n",
      "6/6, loss: 0.145\n",
      "epoch 206/1000, average loss: 0.107\n",
      "6/6, loss: 0.116\n",
      "epoch 207/1000, average loss: 0.101\n",
      "6/6, loss: 0.104\n",
      "epoch 208/1000, average loss: 0.102\n",
      "6/6, loss: 0.063\n",
      "epoch 209/1000, average loss: 0.094\n",
      "6/6, loss: 0.103\n",
      "epoch 210/1000, average loss: 0.101\n",
      "6/6, loss: 0.151\n",
      "epoch 211/1000, average loss: 0.107\n",
      "6/6, loss: 0.149\n",
      "epoch 212/1000, average loss: 0.107\n",
      "6/6, loss: 0.064\n",
      "epoch 213/1000, average loss: 0.095\n",
      "6/6, loss: 0.078\n",
      "epoch 214/1000, average loss: 0.096\n",
      "6/6, loss: 0.117\n",
      "epoch 215/1000, average loss: 0.102\n",
      "6/6, loss: 0.066\n",
      "epoch 216/1000, average loss: 0.095\n",
      "6/6, loss: 0.026\n",
      "epoch 217/1000, average loss: 0.092\n",
      "6/6, loss: 0.107\n",
      "epoch 218/1000, average loss: 0.102\n",
      "6/6, loss: 0.089\n",
      "epoch 219/1000, average loss: 0.101\n",
      "6/6, loss: 0.056\n",
      "epoch 220/1000, average loss: 0.094\n",
      "6/6, loss: 0.083\n",
      "epoch 221/1000, average loss: 0.099\n",
      "6/6, loss: 0.056\n",
      "epoch 222/1000, average loss: 0.094\n",
      "6/6, loss: 0.056\n",
      "epoch 223/1000, average loss: 0.096\n",
      "6/6, loss: 0.056\n",
      "epoch 224/1000, average loss: 0.096\n",
      "6/6, loss: 0.081\n",
      "epoch 225/1000, average loss: 0.098\n",
      "6/6, loss: 0.186\n",
      "epoch 226/1000, average loss: 0.110\n",
      "6/6, loss: 0.065\n",
      "epoch 227/1000, average loss: 0.096\n",
      "6/6, loss: 0.063\n",
      "epoch 228/1000, average loss: 0.096\n",
      "6/6, loss: 0.133\n",
      "epoch 229/1000, average loss: 0.104\n",
      "6/6, loss: 0.129\n",
      "epoch 230/1000, average loss: 0.105\n",
      "6/6, loss: 0.149\n",
      "epoch 231/1000, average loss: 0.106\n",
      "6/6, loss: 0.085\n",
      "epoch 232/1000, average loss: 0.098\n",
      "6/6, loss: 0.157\n",
      "epoch 233/1000, average loss: 0.108\n",
      "6/6, loss: 0.088\n",
      "epoch 234/1000, average loss: 0.098\n",
      "6/6, loss: 0.152\n",
      "epoch 235/1000, average loss: 0.108\n",
      "6/6, loss: 0.085\n",
      "epoch 236/1000, average loss: 0.096\n",
      "6/6, loss: 0.116\n",
      "epoch 237/1000, average loss: 0.103\n",
      "6/6, loss: 0.026\n",
      "epoch 238/1000, average loss: 0.090\n",
      "6/6, loss: 0.182\n",
      "epoch 239/1000, average loss: 0.108\n",
      "6/6, loss: 0.119\n",
      "epoch 240/1000, average loss: 0.104\n",
      "6/6, loss: 0.025\n",
      "epoch 241/1000, average loss: 0.093\n",
      "6/6, loss: 0.025\n",
      "epoch 242/1000, average loss: 0.092\n",
      "6/6, loss: 0.105\n",
      "epoch 243/1000, average loss: 0.101\n",
      "6/6, loss: 0.025\n",
      "epoch 244/1000, average loss: 0.091\n",
      "6/6, loss: 0.126\n",
      "epoch 245/1000, average loss: 0.103\n",
      "6/6, loss: 0.057\n",
      "epoch 246/1000, average loss: 0.095\n",
      "6/6, loss: 0.057\n",
      "epoch 247/1000, average loss: 0.094\n",
      "6/6, loss: 0.194\n",
      "epoch 248/1000, average loss: 0.112\n",
      "6/6, loss: 0.056\n",
      "epoch 249/1000, average loss: 0.094\n",
      "6/6, loss: 0.064\n",
      "epoch 250/1000, average loss: 0.097\n",
      "6/6, loss: 0.127\n",
      "epoch 251/1000, average loss: 0.105\n",
      "6/6, loss: 0.148\n",
      "epoch 252/1000, average loss: 0.108\n",
      "6/6, loss: 0.064\n",
      "epoch 253/1000, average loss: 0.095\n",
      "6/6, loss: 0.180\n",
      "epoch 254/1000, average loss: 0.112\n",
      "6/6, loss: 0.119\n",
      "epoch 255/1000, average loss: 0.102\n",
      "6/6, loss: 0.127\n",
      "epoch 256/1000, average loss: 0.105\n",
      "6/6, loss: 0.126\n",
      "epoch 257/1000, average loss: 0.105\n",
      "6/6, loss: 0.066\n",
      "epoch 258/1000, average loss: 0.097\n",
      "6/6, loss: 0.101\n",
      "epoch 259/1000, average loss: 0.102\n",
      "6/6, loss: 0.064\n",
      "epoch 260/1000, average loss: 0.100\n",
      "6/6, loss: 0.026\n",
      "epoch 261/1000, average loss: 0.091\n",
      "6/6, loss: 0.191\n",
      "epoch 262/1000, average loss: 0.114\n",
      "6/6, loss: 0.025\n",
      "epoch 263/1000, average loss: 0.093\n",
      "6/6, loss: 0.063\n",
      "epoch 264/1000, average loss: 0.096\n",
      "6/6, loss: 0.063\n",
      "epoch 265/1000, average loss: 0.094\n",
      "6/6, loss: 0.064\n",
      "epoch 266/1000, average loss: 0.097\n",
      "6/6, loss: 0.154\n",
      "epoch 267/1000, average loss: 0.108\n",
      "6/6, loss: 0.106\n",
      "epoch 268/1000, average loss: 0.102\n",
      "6/6, loss: 0.069\n",
      "epoch 269/1000, average loss: 0.099\n",
      "6/6, loss: 0.104\n",
      "epoch 270/1000, average loss: 0.099\n",
      "6/6, loss: 0.025\n",
      "epoch 271/1000, average loss: 0.091\n",
      "6/6, loss: 0.024\n",
      "epoch 272/1000, average loss: 0.091\n",
      "6/6, loss: 0.065\n",
      "epoch 273/1000, average loss: 0.095\n",
      "6/6, loss: 0.086\n",
      "epoch 274/1000, average loss: 0.098\n",
      "6/6, loss: 0.082\n",
      "epoch 275/1000, average loss: 0.098\n",
      "6/6, loss: 0.058\n",
      "epoch 276/1000, average loss: 0.097\n",
      "6/6, loss: 0.116\n",
      "epoch 277/1000, average loss: 0.100\n",
      "6/6, loss: 0.061\n",
      "epoch 278/1000, average loss: 0.096\n",
      "6/6, loss: 0.102\n",
      "epoch 279/1000, average loss: 0.100\n",
      "6/6, loss: 0.121\n",
      "epoch 280/1000, average loss: 0.103\n",
      "6/6, loss: 0.091\n",
      "epoch 281/1000, average loss: 0.098\n",
      "6/6, loss: 0.063\n",
      "epoch 282/1000, average loss: 0.096\n",
      "6/6, loss: 0.130\n",
      "epoch 283/1000, average loss: 0.103\n",
      "6/6, loss: 0.068\n",
      "epoch 284/1000, average loss: 0.097\n",
      "6/6, loss: 0.059\n",
      "epoch 285/1000, average loss: 0.095\n",
      "6/6, loss: 0.105\n",
      "epoch 286/1000, average loss: 0.100\n",
      "6/6, loss: 0.130\n",
      "epoch 287/1000, average loss: 0.104\n",
      "6/6, loss: 0.083\n",
      "epoch 288/1000, average loss: 0.097\n",
      "6/6, loss: 0.060\n",
      "epoch 289/1000, average loss: 0.095\n",
      "6/6, loss: 0.062\n",
      "epoch 290/1000, average loss: 0.094\n",
      "6/6, loss: 0.063\n",
      "epoch 291/1000, average loss: 0.097\n",
      "6/6, loss: 0.056\n",
      "epoch 292/1000, average loss: 0.095\n",
      "6/6, loss: 0.190\n",
      "epoch 293/1000, average loss: 0.109\n",
      "6/6, loss: 0.105\n",
      "epoch 294/1000, average loss: 0.101\n",
      "6/6, loss: 0.138\n",
      "epoch 295/1000, average loss: 0.103\n",
      "6/6, loss: 0.095\n",
      "epoch 296/1000, average loss: 0.099\n",
      "6/6, loss: 0.084\n",
      "epoch 297/1000, average loss: 0.098\n",
      "6/6, loss: 0.180\n",
      "epoch 298/1000, average loss: 0.107\n",
      "6/6, loss: 0.024\n",
      "epoch 299/1000, average loss: 0.091\n",
      "6/6, loss: 0.056\n",
      "epoch 300/1000, average loss: 0.094\n",
      "6/6, loss: 0.025\n",
      "epoch 301/1000, average loss: 0.092\n",
      "6/6, loss: 0.063\n",
      "epoch 302/1000, average loss: 0.094\n",
      "6/6, loss: 0.183\n",
      "epoch 303/1000, average loss: 0.112\n",
      "6/6, loss: 0.056\n",
      "epoch 304/1000, average loss: 0.096\n",
      "6/6, loss: 0.135\n",
      "epoch 305/1000, average loss: 0.108\n",
      "6/6, loss: 0.131\n",
      "epoch 306/1000, average loss: 0.104\n",
      "6/6, loss: 0.145\n",
      "epoch 307/1000, average loss: 0.105\n",
      "6/6, loss: 0.115\n",
      "epoch 308/1000, average loss: 0.099\n",
      "6/6, loss: 0.080\n",
      "epoch 309/1000, average loss: 0.096\n",
      "6/6, loss: 0.055\n",
      "epoch 310/1000, average loss: 0.093\n",
      "6/6, loss: 0.084\n",
      "epoch 311/1000, average loss: 0.096\n",
      "6/6, loss: 0.185\n",
      "epoch 312/1000, average loss: 0.109\n",
      "6/6, loss: 0.141\n",
      "epoch 313/1000, average loss: 0.105\n",
      "6/6, loss: 0.023\n",
      "epoch 314/1000, average loss: 0.088\n",
      "6/6, loss: 0.064\n",
      "epoch 315/1000, average loss: 0.093\n",
      "6/6, loss: 0.077\n",
      "epoch 316/1000, average loss: 0.097\n",
      "6/6, loss: 0.151\n",
      "epoch 317/1000, average loss: 0.108\n",
      "6/6, loss: 0.108\n",
      "epoch 318/1000, average loss: 0.101\n",
      "6/6, loss: 0.124\n",
      "epoch 319/1000, average loss: 0.101\n",
      "6/6, loss: 0.142\n",
      "epoch 320/1000, average loss: 0.106\n",
      "6/6, loss: 0.151\n",
      "epoch 321/1000, average loss: 0.106\n",
      "6/6, loss: 0.094\n",
      "epoch 322/1000, average loss: 0.101\n",
      "6/6, loss: 0.102\n",
      "epoch 323/1000, average loss: 0.099\n",
      "6/6, loss: 0.087\n",
      "epoch 324/1000, average loss: 0.096\n",
      "6/6, loss: 0.064\n",
      "epoch 325/1000, average loss: 0.094\n",
      "6/6, loss: 0.061\n",
      "epoch 326/1000, average loss: 0.094\n",
      "6/6, loss: 0.143\n",
      "epoch 327/1000, average loss: 0.106\n",
      "6/6, loss: 0.141\n",
      "epoch 328/1000, average loss: 0.104\n",
      "6/6, loss: 0.084\n",
      "epoch 329/1000, average loss: 0.098\n",
      "6/6, loss: 0.080\n",
      "epoch 330/1000, average loss: 0.099\n",
      "6/6, loss: 0.141\n",
      "epoch 331/1000, average loss: 0.106\n",
      "6/6, loss: 0.084\n",
      "epoch 332/1000, average loss: 0.096\n",
      "6/6, loss: 0.055\n",
      "epoch 333/1000, average loss: 0.093\n",
      "6/6, loss: 0.081\n",
      "epoch 334/1000, average loss: 0.095\n",
      "6/6, loss: 0.171\n",
      "epoch 335/1000, average loss: 0.110\n",
      "6/6, loss: 0.181\n",
      "epoch 336/1000, average loss: 0.109\n",
      "6/6, loss: 0.067\n",
      "epoch 337/1000, average loss: 0.095\n",
      "6/6, loss: 0.084\n",
      "epoch 338/1000, average loss: 0.101\n",
      "6/6, loss: 0.063\n",
      "epoch 339/1000, average loss: 0.098\n",
      "6/6, loss: 0.138\n",
      "epoch 340/1000, average loss: 0.104\n",
      "6/6, loss: 0.102\n",
      "epoch 341/1000, average loss: 0.098\n",
      "6/6, loss: 0.121\n",
      "epoch 342/1000, average loss: 0.101\n",
      "6/6, loss: 0.063\n",
      "epoch 343/1000, average loss: 0.095\n",
      "6/6, loss: 0.055\n",
      "epoch 344/1000, average loss: 0.094\n",
      "6/6, loss: 0.148\n",
      "epoch 345/1000, average loss: 0.103\n",
      "6/6, loss: 0.069\n",
      "epoch 346/1000, average loss: 0.096\n",
      "6/6, loss: 0.084\n",
      "epoch 347/1000, average loss: 0.097\n",
      "6/6, loss: 0.085\n",
      "epoch 348/1000, average loss: 0.096\n",
      "6/6, loss: 0.143\n",
      "epoch 349/1000, average loss: 0.105\n",
      "6/6, loss: 0.146\n",
      "epoch 350/1000, average loss: 0.104\n",
      "6/6, loss: 0.152\n",
      "epoch 351/1000, average loss: 0.106\n",
      "6/6, loss: 0.070\n",
      "epoch 352/1000, average loss: 0.095\n",
      "6/6, loss: 0.144\n",
      "epoch 353/1000, average loss: 0.104\n",
      "6/6, loss: 0.139\n",
      "epoch 354/1000, average loss: 0.104\n",
      "6/6, loss: 0.081\n",
      "epoch 355/1000, average loss: 0.095\n",
      "6/6, loss: 0.024\n",
      "epoch 356/1000, average loss: 0.088\n",
      "6/6, loss: 0.065\n",
      "epoch 357/1000, average loss: 0.093\n",
      "6/6, loss: 0.056\n",
      "epoch 358/1000, average loss: 0.095\n",
      "6/6, loss: 0.023\n",
      "epoch 359/1000, average loss: 0.088\n",
      "6/6, loss: 0.181\n",
      "epoch 360/1000, average loss: 0.109\n",
      "6/6, loss: 0.177\n",
      "epoch 361/1000, average loss: 0.108\n",
      "6/6, loss: 0.084\n",
      "epoch 362/1000, average loss: 0.099\n",
      "6/6, loss: 0.109\n",
      "epoch 363/1000, average loss: 0.102\n",
      "6/6, loss: 0.065\n",
      "epoch 364/1000, average loss: 0.095\n",
      "6/6, loss: 0.141\n",
      "epoch 365/1000, average loss: 0.104\n",
      "6/6, loss: 0.115\n",
      "epoch 366/1000, average loss: 0.102\n",
      "6/6, loss: 0.085\n",
      "epoch 367/1000, average loss: 0.097\n",
      "6/6, loss: 0.145\n",
      "epoch 368/1000, average loss: 0.106\n",
      "6/6, loss: 0.129\n",
      "epoch 369/1000, average loss: 0.103\n",
      "6/6, loss: 0.067\n",
      "epoch 370/1000, average loss: 0.096\n",
      "6/6, loss: 0.092\n",
      "epoch 371/1000, average loss: 0.098\n",
      "6/6, loss: 0.023\n",
      "epoch 372/1000, average loss: 0.089\n",
      "6/6, loss: 0.063\n",
      "epoch 373/1000, average loss: 0.094\n",
      "6/6, loss: 0.054\n",
      "epoch 374/1000, average loss: 0.094\n",
      "6/6, loss: 0.065\n",
      "epoch 375/1000, average loss: 0.096\n",
      "6/6, loss: 0.052\n",
      "epoch 376/1000, average loss: 0.093\n",
      "6/6, loss: 0.024\n",
      "epoch 377/1000, average loss: 0.093\n",
      "6/6, loss: 0.140\n",
      "epoch 378/1000, average loss: 0.104\n",
      "6/6, loss: 0.024\n",
      "epoch 379/1000, average loss: 0.089\n",
      "6/6, loss: 0.122\n",
      "epoch 380/1000, average loss: 0.101\n",
      "6/6, loss: 0.102\n",
      "epoch 381/1000, average loss: 0.100\n",
      "6/6, loss: 0.141\n",
      "epoch 382/1000, average loss: 0.104\n",
      "6/6, loss: 0.150\n",
      "epoch 383/1000, average loss: 0.106\n",
      "6/6, loss: 0.146\n",
      "epoch 384/1000, average loss: 0.103\n",
      "6/6, loss: 0.115\n",
      "epoch 385/1000, average loss: 0.101\n",
      "6/6, loss: 0.141\n",
      "epoch 386/1000, average loss: 0.104\n",
      "6/6, loss: 0.139\n",
      "epoch 387/1000, average loss: 0.104\n",
      "6/6, loss: 0.064\n",
      "epoch 388/1000, average loss: 0.094\n",
      "6/6, loss: 0.101\n",
      "epoch 389/1000, average loss: 0.099\n",
      "6/6, loss: 0.060\n",
      "epoch 390/1000, average loss: 0.093\n",
      "6/6, loss: 0.085\n",
      "epoch 391/1000, average loss: 0.096\n",
      "6/6, loss: 0.066\n",
      "epoch 392/1000, average loss: 0.096\n",
      "6/6, loss: 0.140\n",
      "epoch 393/1000, average loss: 0.102\n",
      "6/6, loss: 0.137\n",
      "epoch 394/1000, average loss: 0.104\n",
      "6/6, loss: 0.065\n",
      "epoch 395/1000, average loss: 0.093\n",
      "6/6, loss: 0.178\n",
      "epoch 396/1000, average loss: 0.106\n",
      "6/6, loss: 0.065\n",
      "epoch 397/1000, average loss: 0.097\n",
      "6/6, loss: 0.064\n",
      "epoch 398/1000, average loss: 0.093\n",
      "6/6, loss: 0.133\n",
      "epoch 399/1000, average loss: 0.106\n",
      "6/6, loss: 0.116\n",
      "epoch 400/1000, average loss: 0.102\n",
      "6/6, loss: 0.129\n",
      "epoch 401/1000, average loss: 0.103\n",
      "6/6, loss: 0.072\n",
      "epoch 402/1000, average loss: 0.095\n",
      "6/6, loss: 0.101\n",
      "epoch 403/1000, average loss: 0.102\n",
      "6/6, loss: 0.089\n",
      "epoch 404/1000, average loss: 0.099\n",
      "6/6, loss: 0.056\n",
      "epoch 405/1000, average loss: 0.093\n",
      "6/6, loss: 0.138\n",
      "epoch 406/1000, average loss: 0.103\n",
      "6/6, loss: 0.102\n",
      "epoch 407/1000, average loss: 0.100\n",
      "6/6, loss: 0.024\n",
      "epoch 408/1000, average loss: 0.091\n",
      "6/6, loss: 0.099\n",
      "epoch 409/1000, average loss: 0.098\n",
      "6/6, loss: 0.111\n",
      "epoch 410/1000, average loss: 0.101\n",
      "6/6, loss: 0.099\n",
      "epoch 411/1000, average loss: 0.103\n",
      "6/6, loss: 0.142\n",
      "epoch 412/1000, average loss: 0.107\n",
      "6/6, loss: 0.138\n",
      "epoch 413/1000, average loss: 0.103\n",
      "6/6, loss: 0.064\n",
      "epoch 414/1000, average loss: 0.096\n",
      "6/6, loss: 0.178\n",
      "epoch 415/1000, average loss: 0.111\n",
      "6/6, loss: 0.179\n",
      "epoch 416/1000, average loss: 0.110\n",
      "6/6, loss: 0.150\n",
      "epoch 417/1000, average loss: 0.106\n",
      "6/6, loss: 0.153\n",
      "epoch 418/1000, average loss: 0.105\n",
      "6/6, loss: 0.138\n",
      "epoch 419/1000, average loss: 0.105\n",
      "6/6, loss: 0.098\n",
      "epoch 420/1000, average loss: 0.100\n",
      "6/6, loss: 0.022\n",
      "epoch 421/1000, average loss: 0.090\n",
      "6/6, loss: 0.062\n",
      "epoch 422/1000, average loss: 0.095\n",
      "6/6, loss: 0.056\n",
      "epoch 423/1000, average loss: 0.095\n",
      "6/6, loss: 0.067\n",
      "epoch 424/1000, average loss: 0.096\n",
      "6/6, loss: 0.131\n",
      "epoch 425/1000, average loss: 0.103\n",
      "6/6, loss: 0.115\n",
      "epoch 426/1000, average loss: 0.101\n",
      "6/6, loss: 0.093\n",
      "epoch 427/1000, average loss: 0.099\n",
      "6/6, loss: 0.148\n",
      "epoch 428/1000, average loss: 0.104\n",
      "6/6, loss: 0.104\n",
      "epoch 429/1000, average loss: 0.099\n",
      "6/6, loss: 0.115\n",
      "epoch 430/1000, average loss: 0.101\n",
      "6/6, loss: 0.072\n",
      "epoch 431/1000, average loss: 0.096\n",
      "6/6, loss: 0.062\n",
      "epoch 432/1000, average loss: 0.095\n",
      "6/6, loss: 0.081\n",
      "epoch 433/1000, average loss: 0.095\n",
      "6/6, loss: 0.153\n",
      "epoch 434/1000, average loss: 0.106\n",
      "6/6, loss: 0.063\n",
      "epoch 435/1000, average loss: 0.096\n",
      "6/6, loss: 0.149\n",
      "epoch 436/1000, average loss: 0.105\n",
      "6/6, loss: 0.169\n",
      "epoch 437/1000, average loss: 0.107\n",
      "6/6, loss: 0.065\n",
      "epoch 438/1000, average loss: 0.093\n",
      "6/6, loss: 0.050\n",
      "epoch 439/1000, average loss: 0.093\n",
      "6/6, loss: 0.022\n",
      "epoch 440/1000, average loss: 0.089\n",
      "6/6, loss: 0.067\n",
      "epoch 441/1000, average loss: 0.096\n",
      "6/6, loss: 0.102\n",
      "epoch 442/1000, average loss: 0.101\n",
      "6/6, loss: 0.103\n",
      "epoch 443/1000, average loss: 0.102\n",
      "6/6, loss: 0.121\n",
      "epoch 444/1000, average loss: 0.099\n",
      "6/6, loss: 0.140\n",
      "epoch 445/1000, average loss: 0.104\n",
      "6/6, loss: 0.056\n",
      "epoch 446/1000, average loss: 0.096\n",
      "6/6, loss: 0.119\n",
      "epoch 447/1000, average loss: 0.100\n",
      "6/6, loss: 0.085\n",
      "epoch 448/1000, average loss: 0.099\n",
      "6/6, loss: 0.130\n",
      "epoch 449/1000, average loss: 0.102\n",
      "6/6, loss: 0.064\n",
      "epoch 450/1000, average loss: 0.095\n",
      "6/6, loss: 0.066\n",
      "epoch 451/1000, average loss: 0.095\n",
      "6/6, loss: 0.023\n",
      "epoch 452/1000, average loss: 0.090\n",
      "6/6, loss: 0.102\n",
      "epoch 453/1000, average loss: 0.098\n",
      "6/6, loss: 0.148\n",
      "epoch 454/1000, average loss: 0.104\n",
      "6/6, loss: 0.105\n",
      "epoch 455/1000, average loss: 0.100\n",
      "6/6, loss: 0.102\n",
      "epoch 456/1000, average loss: 0.098\n",
      "6/6, loss: 0.065\n",
      "epoch 457/1000, average loss: 0.094\n",
      "6/6, loss: 0.056\n",
      "epoch 458/1000, average loss: 0.091\n",
      "6/6, loss: 0.053\n",
      "epoch 459/1000, average loss: 0.092\n",
      "6/6, loss: 0.143\n",
      "epoch 460/1000, average loss: 0.103\n",
      "6/6, loss: 0.121\n",
      "epoch 461/1000, average loss: 0.099\n",
      "6/6, loss: 0.179\n",
      "epoch 462/1000, average loss: 0.109\n",
      "6/6, loss: 0.107\n",
      "epoch 463/1000, average loss: 0.105\n",
      "6/6, loss: 0.144\n",
      "epoch 464/1000, average loss: 0.110\n",
      "6/6, loss: 0.117\n",
      "epoch 465/1000, average loss: 0.105\n",
      "6/6, loss: 0.138\n",
      "epoch 466/1000, average loss: 0.105\n",
      "6/6, loss: 0.144\n",
      "epoch 467/1000, average loss: 0.107\n",
      "6/6, loss: 0.132\n",
      "epoch 468/1000, average loss: 0.105\n",
      "6/6, loss: 0.180\n",
      "epoch 469/1000, average loss: 0.112\n",
      "6/6, loss: 0.081\n",
      "epoch 470/1000, average loss: 0.098\n",
      "6/6, loss: 0.105\n",
      "epoch 471/1000, average loss: 0.100\n",
      "6/6, loss: 0.103\n",
      "epoch 472/1000, average loss: 0.098\n",
      "6/6, loss: 0.178\n",
      "epoch 473/1000, average loss: 0.111\n",
      "6/6, loss: 0.024\n",
      "epoch 474/1000, average loss: 0.091\n",
      "6/6, loss: 0.055\n",
      "epoch 475/1000, average loss: 0.095\n",
      "6/6, loss: 0.176\n",
      "epoch 476/1000, average loss: 0.107\n",
      "6/6, loss: 0.102\n",
      "epoch 477/1000, average loss: 0.099\n",
      "6/6, loss: 0.121\n",
      "epoch 478/1000, average loss: 0.101\n",
      "6/6, loss: 0.171\n",
      "epoch 479/1000, average loss: 0.111\n",
      "6/6, loss: 0.129\n",
      "epoch 480/1000, average loss: 0.104\n",
      "6/6, loss: 0.083\n",
      "epoch 481/1000, average loss: 0.096\n",
      "6/6, loss: 0.082\n",
      "epoch 482/1000, average loss: 0.098\n",
      "6/6, loss: 0.064\n",
      "epoch 483/1000, average loss: 0.094\n",
      "6/6, loss: 0.061\n",
      "epoch 484/1000, average loss: 0.093\n",
      "6/6, loss: 0.194\n",
      "epoch 485/1000, average loss: 0.113\n",
      "6/6, loss: 0.090\n",
      "epoch 486/1000, average loss: 0.098\n",
      "6/6, loss: 0.124\n",
      "epoch 487/1000, average loss: 0.104\n",
      "6/6, loss: 0.152\n",
      "epoch 488/1000, average loss: 0.107\n",
      "6/6, loss: 0.129\n",
      "epoch 489/1000, average loss: 0.103\n",
      "6/6, loss: 0.142\n",
      "epoch 490/1000, average loss: 0.105\n",
      "6/6, loss: 0.067\n",
      "epoch 491/1000, average loss: 0.094\n",
      "6/6, loss: 0.141\n",
      "epoch 492/1000, average loss: 0.106\n",
      "6/6, loss: 0.054\n",
      "epoch 493/1000, average loss: 0.095\n",
      "6/6, loss: 0.177\n",
      "epoch 494/1000, average loss: 0.106\n",
      "6/6, loss: 0.139\n",
      "epoch 495/1000, average loss: 0.102\n",
      "6/6, loss: 0.120\n",
      "epoch 496/1000, average loss: 0.100\n",
      "6/6, loss: 0.148\n",
      "epoch 497/1000, average loss: 0.106\n",
      "6/6, loss: 0.117\n",
      "epoch 498/1000, average loss: 0.100\n",
      "6/6, loss: 0.061\n",
      "epoch 499/1000, average loss: 0.094\n",
      "6/6, loss: 0.065\n",
      "epoch 500/1000, average loss: 0.097\n",
      "6/6, loss: 0.066\n",
      "epoch 501/1000, average loss: 0.092\n",
      "6/6, loss: 0.156\n",
      "epoch 502/1000, average loss: 0.106\n",
      "6/6, loss: 0.179\n",
      "epoch 503/1000, average loss: 0.108\n",
      "6/6, loss: 0.058\n",
      "epoch 504/1000, average loss: 0.097\n",
      "6/6, loss: 0.063\n",
      "epoch 505/1000, average loss: 0.094\n",
      "6/6, loss: 0.145\n",
      "epoch 506/1000, average loss: 0.108\n",
      "6/6, loss: 0.055\n",
      "epoch 507/1000, average loss: 0.093\n",
      "6/6, loss: 0.081\n",
      "epoch 508/1000, average loss: 0.097\n",
      "6/6, loss: 0.055\n",
      "epoch 509/1000, average loss: 0.092\n",
      "6/6, loss: 0.152\n",
      "epoch 510/1000, average loss: 0.107\n",
      "6/6, loss: 0.056\n",
      "epoch 511/1000, average loss: 0.093\n",
      "6/6, loss: 0.116\n",
      "epoch 512/1000, average loss: 0.098\n",
      "6/6, loss: 0.067\n",
      "epoch 513/1000, average loss: 0.096\n",
      "6/6, loss: 0.104\n",
      "epoch 514/1000, average loss: 0.099\n",
      "6/6, loss: 0.061\n",
      "epoch 515/1000, average loss: 0.092\n",
      "6/6, loss: 0.148\n",
      "epoch 516/1000, average loss: 0.107\n",
      "6/6, loss: 0.118\n",
      "epoch 517/1000, average loss: 0.102\n",
      "6/6, loss: 0.102\n",
      "epoch 518/1000, average loss: 0.100\n",
      "6/6, loss: 0.142\n",
      "epoch 519/1000, average loss: 0.104\n",
      "6/6, loss: 0.137\n",
      "epoch 520/1000, average loss: 0.102\n",
      "6/6, loss: 0.101\n",
      "epoch 521/1000, average loss: 0.100\n",
      "6/6, loss: 0.052\n",
      "epoch 522/1000, average loss: 0.093\n",
      "6/6, loss: 0.065\n",
      "epoch 523/1000, average loss: 0.093\n",
      "6/6, loss: 0.120\n",
      "epoch 524/1000, average loss: 0.103\n",
      "6/6, loss: 0.103\n",
      "epoch 525/1000, average loss: 0.099\n",
      "6/6, loss: 0.121\n",
      "epoch 526/1000, average loss: 0.101\n",
      "6/6, loss: 0.140\n",
      "epoch 527/1000, average loss: 0.105\n",
      "6/6, loss: 0.054\n",
      "epoch 528/1000, average loss: 0.092\n",
      "6/6, loss: 0.101\n",
      "epoch 529/1000, average loss: 0.098\n",
      "6/6, loss: 0.150\n",
      "epoch 530/1000, average loss: 0.104\n",
      "6/6, loss: 0.023\n",
      "epoch 531/1000, average loss: 0.088\n",
      "6/6, loss: 0.101\n",
      "epoch 532/1000, average loss: 0.101\n",
      "6/6, loss: 0.148\n",
      "epoch 533/1000, average loss: 0.105\n",
      "6/6, loss: 0.117\n",
      "epoch 534/1000, average loss: 0.100\n",
      "6/6, loss: 0.103\n",
      "epoch 535/1000, average loss: 0.098\n",
      "6/6, loss: 0.082\n",
      "epoch 536/1000, average loss: 0.095\n",
      "6/6, loss: 0.050\n",
      "epoch 537/1000, average loss: 0.091\n",
      "6/6, loss: 0.052\n",
      "epoch 538/1000, average loss: 0.092\n",
      "6/6, loss: 0.064\n",
      "epoch 539/1000, average loss: 0.097\n",
      "6/6, loss: 0.084\n",
      "epoch 540/1000, average loss: 0.094\n",
      "6/6, loss: 0.116\n",
      "epoch 541/1000, average loss: 0.098\n",
      "6/6, loss: 0.175\n",
      "epoch 542/1000, average loss: 0.108\n",
      "6/6, loss: 0.114\n",
      "epoch 543/1000, average loss: 0.099\n",
      "6/6, loss: 0.050\n",
      "epoch 544/1000, average loss: 0.092\n",
      "6/6, loss: 0.051\n",
      "epoch 545/1000, average loss: 0.092\n",
      "6/6, loss: 0.101\n",
      "epoch 546/1000, average loss: 0.099\n",
      "6/6, loss: 0.069\n",
      "epoch 547/1000, average loss: 0.094\n",
      "6/6, loss: 0.104\n",
      "epoch 548/1000, average loss: 0.100\n",
      "6/6, loss: 0.105\n",
      "epoch 549/1000, average loss: 0.098\n",
      "6/6, loss: 0.148\n",
      "epoch 550/1000, average loss: 0.105\n",
      "6/6, loss: 0.121\n",
      "epoch 551/1000, average loss: 0.103\n",
      "6/6, loss: 0.151\n",
      "epoch 552/1000, average loss: 0.106\n",
      "6/6, loss: 0.141\n",
      "epoch 553/1000, average loss: 0.104\n",
      "6/6, loss: 0.097\n",
      "epoch 554/1000, average loss: 0.099\n",
      "6/6, loss: 0.127\n",
      "epoch 555/1000, average loss: 0.101\n",
      "6/6, loss: 0.173\n",
      "epoch 556/1000, average loss: 0.109\n",
      "6/6, loss: 0.174\n",
      "epoch 557/1000, average loss: 0.107\n",
      "6/6, loss: 0.148\n",
      "epoch 558/1000, average loss: 0.105\n",
      "6/6, loss: 0.104\n",
      "epoch 559/1000, average loss: 0.099\n",
      "6/6, loss: 0.101\n",
      "epoch 560/1000, average loss: 0.101\n",
      "6/6, loss: 0.121\n",
      "epoch 561/1000, average loss: 0.102\n",
      "6/6, loss: 0.147\n",
      "epoch 562/1000, average loss: 0.105\n",
      "6/6, loss: 0.055\n",
      "epoch 563/1000, average loss: 0.093\n",
      "6/6, loss: 0.116\n",
      "epoch 564/1000, average loss: 0.104\n",
      "6/6, loss: 0.105\n",
      "epoch 565/1000, average loss: 0.099\n",
      "6/6, loss: 0.064\n",
      "epoch 566/1000, average loss: 0.099\n",
      "6/6, loss: 0.124\n",
      "epoch 567/1000, average loss: 0.104\n",
      "6/6, loss: 0.066\n",
      "epoch 568/1000, average loss: 0.096\n",
      "6/6, loss: 0.101\n",
      "epoch 569/1000, average loss: 0.100\n",
      "6/6, loss: 0.148\n",
      "epoch 570/1000, average loss: 0.106\n",
      "6/6, loss: 0.086\n",
      "epoch 571/1000, average loss: 0.097\n",
      "6/6, loss: 0.131\n",
      "epoch 572/1000, average loss: 0.104\n",
      "6/6, loss: 0.147\n",
      "epoch 573/1000, average loss: 0.105\n",
      "6/6, loss: 0.065\n",
      "epoch 574/1000, average loss: 0.094\n",
      "6/6, loss: 0.141\n",
      "epoch 575/1000, average loss: 0.103\n",
      "6/6, loss: 0.104\n",
      "epoch 576/1000, average loss: 0.099\n",
      "6/6, loss: 0.146\n",
      "epoch 577/1000, average loss: 0.103\n",
      "6/6, loss: 0.138\n",
      "epoch 578/1000, average loss: 0.102\n",
      "6/6, loss: 0.068\n",
      "epoch 579/1000, average loss: 0.094\n",
      "6/6, loss: 0.065\n",
      "epoch 580/1000, average loss: 0.096\n",
      "6/6, loss: 0.055\n",
      "epoch 581/1000, average loss: 0.092\n",
      "6/6, loss: 0.116\n",
      "epoch 582/1000, average loss: 0.106\n",
      "6/6, loss: 0.027\n",
      "epoch 583/1000, average loss: 0.090\n",
      "6/6, loss: 0.082\n",
      "epoch 584/1000, average loss: 0.100\n",
      "6/6, loss: 0.068\n",
      "epoch 585/1000, average loss: 0.099\n",
      "6/6, loss: 0.154\n",
      "epoch 586/1000, average loss: 0.110\n",
      "6/6, loss: 0.171\n",
      "epoch 587/1000, average loss: 0.112\n",
      "6/6, loss: 0.068\n",
      "epoch 588/1000, average loss: 0.097\n",
      "6/6, loss: 0.144\n",
      "epoch 589/1000, average loss: 0.108\n",
      "6/6, loss: 0.129\n",
      "epoch 590/1000, average loss: 0.105\n",
      "6/6, loss: 0.097\n",
      "epoch 591/1000, average loss: 0.101\n",
      "6/6, loss: 0.082\n",
      "epoch 592/1000, average loss: 0.099\n",
      "6/6, loss: 0.172\n",
      "epoch 593/1000, average loss: 0.112\n",
      "6/6, loss: 0.147\n",
      "epoch 594/1000, average loss: 0.108\n",
      "6/6, loss: 0.139\n",
      "epoch 595/1000, average loss: 0.104\n",
      "6/6, loss: 0.068\n",
      "epoch 596/1000, average loss: 0.096\n",
      "6/6, loss: 0.061\n",
      "epoch 597/1000, average loss: 0.093\n",
      "6/6, loss: 0.056\n",
      "epoch 598/1000, average loss: 0.093\n",
      "6/6, loss: 0.137\n",
      "epoch 599/1000, average loss: 0.102\n",
      "6/6, loss: 0.119\n",
      "epoch 600/1000, average loss: 0.101\n",
      "6/6, loss: 0.137\n",
      "epoch 601/1000, average loss: 0.102\n",
      "6/6, loss: 0.122\n",
      "epoch 602/1000, average loss: 0.101\n",
      "6/6, loss: 0.090\n",
      "epoch 603/1000, average loss: 0.098\n",
      "6/6, loss: 0.053\n",
      "epoch 604/1000, average loss: 0.093\n",
      "6/6, loss: 0.087\n",
      "epoch 605/1000, average loss: 0.097\n",
      "6/6, loss: 0.054\n",
      "epoch 606/1000, average loss: 0.093\n",
      "6/6, loss: 0.063\n",
      "epoch 607/1000, average loss: 0.095\n",
      "6/6, loss: 0.062\n",
      "epoch 608/1000, average loss: 0.095\n",
      "6/6, loss: 0.053\n",
      "epoch 609/1000, average loss: 0.096\n",
      "6/6, loss: 0.143\n",
      "epoch 610/1000, average loss: 0.105\n",
      "6/6, loss: 0.141\n",
      "epoch 611/1000, average loss: 0.107\n",
      "6/6, loss: 0.051\n",
      "epoch 612/1000, average loss: 0.092\n",
      "6/6, loss: 0.101\n",
      "epoch 613/1000, average loss: 0.099\n",
      "6/6, loss: 0.147\n",
      "epoch 614/1000, average loss: 0.106\n",
      "6/6, loss: 0.061\n",
      "epoch 615/1000, average loss: 0.093\n",
      "6/6, loss: 0.149\n",
      "epoch 616/1000, average loss: 0.104\n",
      "6/6, loss: 0.129\n",
      "epoch 617/1000, average loss: 0.103\n",
      "6/6, loss: 0.138\n",
      "epoch 618/1000, average loss: 0.104\n",
      "6/6, loss: 0.084\n",
      "epoch 619/1000, average loss: 0.097\n",
      "6/6, loss: 0.105\n",
      "epoch 620/1000, average loss: 0.098\n",
      "6/6, loss: 0.142\n",
      "epoch 621/1000, average loss: 0.108\n",
      "6/6, loss: 0.139\n",
      "epoch 622/1000, average loss: 0.103\n",
      "6/6, loss: 0.054\n",
      "epoch 623/1000, average loss: 0.094\n",
      "6/6, loss: 0.117\n",
      "epoch 624/1000, average loss: 0.099\n",
      "6/6, loss: 0.101\n",
      "epoch 625/1000, average loss: 0.099\n",
      "6/6, loss: 0.100\n",
      "epoch 626/1000, average loss: 0.098\n",
      "6/6, loss: 0.143\n",
      "epoch 627/1000, average loss: 0.107\n",
      "6/6, loss: 0.146\n",
      "epoch 628/1000, average loss: 0.106\n",
      "6/6, loss: 0.062\n",
      "epoch 629/1000, average loss: 0.093\n",
      "6/6, loss: 0.063\n",
      "epoch 630/1000, average loss: 0.093\n",
      "6/6, loss: 0.054\n",
      "epoch 631/1000, average loss: 0.092\n",
      "6/6, loss: 0.103\n",
      "epoch 632/1000, average loss: 0.102\n",
      "6/6, loss: 0.174\n",
      "epoch 633/1000, average loss: 0.109\n",
      "6/6, loss: 0.084\n",
      "epoch 634/1000, average loss: 0.097\n",
      "6/6, loss: 0.149\n",
      "epoch 635/1000, average loss: 0.103\n",
      "6/6, loss: 0.023\n",
      "epoch 636/1000, average loss: 0.088\n",
      "6/6, loss: 0.060\n",
      "epoch 637/1000, average loss: 0.092\n",
      "6/6, loss: 0.170\n",
      "epoch 638/1000, average loss: 0.109\n",
      "6/6, loss: 0.116\n",
      "epoch 639/1000, average loss: 0.101\n",
      "6/6, loss: 0.088\n",
      "epoch 640/1000, average loss: 0.097\n",
      "6/6, loss: 0.144\n",
      "epoch 641/1000, average loss: 0.104\n",
      "6/6, loss: 0.102\n",
      "epoch 642/1000, average loss: 0.102\n",
      "6/6, loss: 0.101\n",
      "epoch 643/1000, average loss: 0.099\n",
      "6/6, loss: 0.053\n",
      "epoch 644/1000, average loss: 0.092\n",
      "6/6, loss: 0.054\n",
      "epoch 645/1000, average loss: 0.092\n",
      "6/6, loss: 0.101\n",
      "epoch 646/1000, average loss: 0.098\n",
      "6/6, loss: 0.120\n",
      "epoch 647/1000, average loss: 0.099\n",
      "6/6, loss: 0.066\n",
      "epoch 648/1000, average loss: 0.096\n",
      "6/6, loss: 0.102\n",
      "epoch 649/1000, average loss: 0.099\n",
      "6/6, loss: 0.099\n",
      "epoch 650/1000, average loss: 0.101\n",
      "6/6, loss: 0.065\n",
      "epoch 651/1000, average loss: 0.093\n",
      "6/6, loss: 0.079\n",
      "epoch 652/1000, average loss: 0.094\n",
      "6/6, loss: 0.023\n",
      "epoch 653/1000, average loss: 0.088\n",
      "6/6, loss: 0.120\n",
      "epoch 654/1000, average loss: 0.099\n",
      "6/6, loss: 0.066\n",
      "epoch 655/1000, average loss: 0.093\n",
      "6/6, loss: 0.179\n",
      "epoch 656/1000, average loss: 0.107\n",
      "6/6, loss: 0.128\n",
      "epoch 657/1000, average loss: 0.105\n",
      "6/6, loss: 0.067\n",
      "epoch 658/1000, average loss: 0.094\n",
      "6/6, loss: 0.120\n",
      "epoch 659/1000, average loss: 0.100\n",
      "6/6, loss: 0.115\n",
      "epoch 660/1000, average loss: 0.101\n",
      "6/6, loss: 0.143\n",
      "epoch 661/1000, average loss: 0.103\n",
      "6/6, loss: 0.175\n",
      "epoch 662/1000, average loss: 0.110\n",
      "6/6, loss: 0.024\n",
      "epoch 663/1000, average loss: 0.089\n",
      "6/6, loss: 0.131\n",
      "epoch 664/1000, average loss: 0.104\n",
      "6/6, loss: 0.138\n",
      "epoch 665/1000, average loss: 0.101\n",
      "6/6, loss: 0.064\n",
      "epoch 666/1000, average loss: 0.093\n",
      "6/6, loss: 0.121\n",
      "epoch 667/1000, average loss: 0.100\n",
      "6/6, loss: 0.119\n",
      "epoch 668/1000, average loss: 0.100\n",
      "6/6, loss: 0.144\n",
      "epoch 669/1000, average loss: 0.104\n",
      "6/6, loss: 0.143\n",
      "epoch 670/1000, average loss: 0.102\n",
      "6/6, loss: 0.063\n",
      "epoch 671/1000, average loss: 0.092\n",
      "6/6, loss: 0.176\n",
      "epoch 672/1000, average loss: 0.106\n",
      "6/6, loss: 0.080\n",
      "epoch 673/1000, average loss: 0.096\n",
      "6/6, loss: 0.151\n",
      "epoch 674/1000, average loss: 0.104\n",
      "6/6, loss: 0.176\n",
      "epoch 675/1000, average loss: 0.105\n",
      "6/6, loss: 0.140\n",
      "epoch 676/1000, average loss: 0.103\n",
      "6/6, loss: 0.022\n",
      "epoch 677/1000, average loss: 0.088\n",
      "6/6, loss: 0.103\n",
      "epoch 678/1000, average loss: 0.101\n",
      "6/6, loss: 0.060\n",
      "epoch 679/1000, average loss: 0.091\n",
      "6/6, loss: 0.071\n",
      "epoch 680/1000, average loss: 0.096\n",
      "6/6, loss: 0.131\n",
      "epoch 681/1000, average loss: 0.105\n",
      "6/6, loss: 0.083\n",
      "epoch 682/1000, average loss: 0.099\n",
      "6/6, loss: 0.137\n",
      "epoch 683/1000, average loss: 0.105\n",
      "6/6, loss: 0.103\n",
      "epoch 684/1000, average loss: 0.099\n",
      "6/6, loss: 0.066\n",
      "epoch 685/1000, average loss: 0.093\n",
      "6/6, loss: 0.116\n",
      "epoch 686/1000, average loss: 0.100\n",
      "6/6, loss: 0.173\n",
      "epoch 687/1000, average loss: 0.110\n",
      "6/6, loss: 0.129\n",
      "epoch 688/1000, average loss: 0.102\n",
      "6/6, loss: 0.140\n",
      "epoch 689/1000, average loss: 0.105\n",
      "6/6, loss: 0.175\n",
      "epoch 690/1000, average loss: 0.106\n",
      "6/6, loss: 0.053\n",
      "epoch 691/1000, average loss: 0.095\n",
      "6/6, loss: 0.082\n",
      "epoch 692/1000, average loss: 0.096\n",
      "6/6, loss: 0.178\n",
      "epoch 693/1000, average loss: 0.107\n",
      "6/6, loss: 0.137\n",
      "epoch 694/1000, average loss: 0.102\n",
      "6/6, loss: 0.151\n",
      "epoch 695/1000, average loss: 0.107\n",
      "6/6, loss: 0.146\n",
      "epoch 696/1000, average loss: 0.103\n",
      "6/6, loss: 0.087\n",
      "epoch 697/1000, average loss: 0.097\n",
      "6/6, loss: 0.122\n",
      "epoch 698/1000, average loss: 0.104\n",
      "6/6, loss: 0.097\n",
      "epoch 699/1000, average loss: 0.098\n",
      "6/6, loss: 0.061\n",
      "epoch 700/1000, average loss: 0.092\n",
      "6/6, loss: 0.064\n",
      "epoch 701/1000, average loss: 0.093\n",
      "6/6, loss: 0.139\n",
      "epoch 702/1000, average loss: 0.102\n",
      "6/6, loss: 0.054\n",
      "epoch 703/1000, average loss: 0.093\n",
      "6/6, loss: 0.081\n",
      "epoch 704/1000, average loss: 0.097\n",
      "6/6, loss: 0.139\n",
      "epoch 705/1000, average loss: 0.102\n",
      "6/6, loss: 0.167\n",
      "epoch 706/1000, average loss: 0.109\n",
      "6/6, loss: 0.103\n",
      "epoch 707/1000, average loss: 0.098\n",
      "6/6, loss: 0.116\n",
      "epoch 708/1000, average loss: 0.099\n",
      "6/6, loss: 0.063\n",
      "epoch 709/1000, average loss: 0.092\n",
      "6/6, loss: 0.102\n",
      "epoch 710/1000, average loss: 0.096\n",
      "6/6, loss: 0.086\n",
      "epoch 711/1000, average loss: 0.097\n",
      "6/6, loss: 0.082\n",
      "epoch 712/1000, average loss: 0.096\n",
      "6/6, loss: 0.054\n",
      "epoch 713/1000, average loss: 0.094\n",
      "6/6, loss: 0.140\n",
      "epoch 714/1000, average loss: 0.104\n",
      "6/6, loss: 0.121\n",
      "epoch 715/1000, average loss: 0.100\n",
      "6/6, loss: 0.066\n",
      "epoch 716/1000, average loss: 0.094\n",
      "6/6, loss: 0.141\n",
      "epoch 717/1000, average loss: 0.102\n",
      "6/6, loss: 0.069\n",
      "epoch 718/1000, average loss: 0.094\n",
      "6/6, loss: 0.101\n",
      "epoch 719/1000, average loss: 0.098\n",
      "6/6, loss: 0.138\n",
      "epoch 720/1000, average loss: 0.103\n",
      "6/6, loss: 0.140\n",
      "epoch 721/1000, average loss: 0.104\n",
      "6/6, loss: 0.102\n",
      "epoch 722/1000, average loss: 0.098\n",
      "6/6, loss: 0.103\n",
      "epoch 723/1000, average loss: 0.097\n",
      "6/6, loss: 0.081\n",
      "epoch 724/1000, average loss: 0.094\n",
      "6/6, loss: 0.102\n",
      "epoch 725/1000, average loss: 0.099\n",
      "6/6, loss: 0.053\n",
      "epoch 726/1000, average loss: 0.092\n",
      "6/6, loss: 0.175\n",
      "epoch 727/1000, average loss: 0.105\n",
      "6/6, loss: 0.147\n",
      "epoch 728/1000, average loss: 0.102\n",
      "6/6, loss: 0.049\n",
      "epoch 729/1000, average loss: 0.091\n",
      "6/6, loss: 0.145\n",
      "epoch 730/1000, average loss: 0.101\n",
      "6/6, loss: 0.099\n",
      "epoch 731/1000, average loss: 0.098\n",
      "6/6, loss: 0.061\n",
      "epoch 732/1000, average loss: 0.092\n",
      "6/6, loss: 0.067\n",
      "epoch 733/1000, average loss: 0.093\n",
      "6/6, loss: 0.063\n",
      "epoch 734/1000, average loss: 0.093\n",
      "6/6, loss: 0.102\n",
      "epoch 735/1000, average loss: 0.097\n",
      "6/6, loss: 0.122\n",
      "epoch 736/1000, average loss: 0.100\n",
      "6/6, loss: 0.080\n",
      "epoch 737/1000, average loss: 0.095\n",
      "6/6, loss: 0.062\n",
      "epoch 738/1000, average loss: 0.092\n",
      "6/6, loss: 0.139\n",
      "epoch 739/1000, average loss: 0.103\n",
      "6/6, loss: 0.148\n",
      "epoch 740/1000, average loss: 0.103\n",
      "6/6, loss: 0.137\n",
      "epoch 741/1000, average loss: 0.100\n",
      "6/6, loss: 0.070\n",
      "epoch 742/1000, average loss: 0.093\n",
      "6/6, loss: 0.081\n",
      "epoch 743/1000, average loss: 0.094\n",
      "6/6, loss: 0.101\n",
      "epoch 744/1000, average loss: 0.097\n",
      "6/6, loss: 0.175\n",
      "epoch 745/1000, average loss: 0.104\n",
      "6/6, loss: 0.149\n",
      "epoch 746/1000, average loss: 0.104\n",
      "6/6, loss: 0.180\n",
      "epoch 747/1000, average loss: 0.107\n",
      "6/6, loss: 0.067\n",
      "epoch 748/1000, average loss: 0.095\n",
      "6/6, loss: 0.153\n",
      "epoch 749/1000, average loss: 0.105\n",
      "6/6, loss: 0.176\n",
      "epoch 750/1000, average loss: 0.107\n",
      "6/6, loss: 0.101\n",
      "epoch 751/1000, average loss: 0.098\n",
      "6/6, loss: 0.101\n",
      "epoch 752/1000, average loss: 0.097\n",
      "6/6, loss: 0.049\n",
      "epoch 753/1000, average loss: 0.090\n",
      "6/6, loss: 0.101\n",
      "epoch 754/1000, average loss: 0.096\n",
      "6/6, loss: 0.062\n",
      "epoch 755/1000, average loss: 0.092\n",
      "6/6, loss: 0.049\n",
      "epoch 756/1000, average loss: 0.092\n",
      "6/6, loss: 0.100\n",
      "epoch 757/1000, average loss: 0.098\n",
      "6/6, loss: 0.103\n",
      "epoch 758/1000, average loss: 0.098\n",
      "6/6, loss: 0.174\n",
      "epoch 759/1000, average loss: 0.109\n",
      "6/6, loss: 0.128\n",
      "epoch 760/1000, average loss: 0.102\n",
      "6/6, loss: 0.065\n",
      "epoch 761/1000, average loss: 0.094\n",
      "6/6, loss: 0.147\n",
      "epoch 762/1000, average loss: 0.104\n",
      "6/6, loss: 0.168\n",
      "epoch 763/1000, average loss: 0.107\n",
      "6/6, loss: 0.056\n",
      "epoch 764/1000, average loss: 0.092\n",
      "6/6, loss: 0.100\n",
      "epoch 765/1000, average loss: 0.099\n",
      "6/6, loss: 0.186\n",
      "epoch 766/1000, average loss: 0.108\n",
      "6/6, loss: 0.148\n",
      "epoch 767/1000, average loss: 0.102\n",
      "6/6, loss: 0.149\n",
      "epoch 768/1000, average loss: 0.104\n",
      "6/6, loss: 0.055\n",
      "epoch 769/1000, average loss: 0.092\n",
      "6/6, loss: 0.116\n",
      "epoch 770/1000, average loss: 0.099\n",
      "6/6, loss: 0.080\n",
      "epoch 771/1000, average loss: 0.095\n",
      "6/6, loss: 0.059\n",
      "epoch 772/1000, average loss: 0.091\n",
      "6/6, loss: 0.123\n",
      "epoch 773/1000, average loss: 0.100\n",
      "6/6, loss: 0.100\n",
      "epoch 774/1000, average loss: 0.096\n",
      "6/6, loss: 0.061\n",
      "epoch 775/1000, average loss: 0.094\n",
      "6/6, loss: 0.059\n",
      "epoch 776/1000, average loss: 0.092\n",
      "6/6, loss: 0.054\n",
      "epoch 777/1000, average loss: 0.094\n",
      "6/6, loss: 0.051\n",
      "epoch 778/1000, average loss: 0.093\n",
      "6/6, loss: 0.142\n",
      "epoch 779/1000, average loss: 0.104\n",
      "6/6, loss: 0.023\n",
      "epoch 780/1000, average loss: 0.090\n",
      "6/6, loss: 0.168\n",
      "epoch 781/1000, average loss: 0.108\n",
      "6/6, loss: 0.101\n",
      "epoch 782/1000, average loss: 0.097\n",
      "6/6, loss: 0.116\n",
      "epoch 783/1000, average loss: 0.100\n",
      "6/6, loss: 0.130\n",
      "epoch 784/1000, average loss: 0.103\n",
      "6/6, loss: 0.167\n",
      "epoch 785/1000, average loss: 0.108\n",
      "6/6, loss: 0.141\n",
      "epoch 786/1000, average loss: 0.104\n",
      "6/6, loss: 0.050\n",
      "epoch 787/1000, average loss: 0.091\n",
      "6/6, loss: 0.065\n",
      "epoch 788/1000, average loss: 0.092\n",
      "6/6, loss: 0.169\n",
      "epoch 789/1000, average loss: 0.107\n",
      "6/6, loss: 0.063\n",
      "epoch 790/1000, average loss: 0.093\n",
      "6/6, loss: 0.137\n",
      "epoch 791/1000, average loss: 0.102\n",
      "6/6, loss: 0.052\n",
      "epoch 792/1000, average loss: 0.092\n",
      "6/6, loss: 0.153\n",
      "epoch 793/1000, average loss: 0.105\n",
      "6/6, loss: 0.087\n",
      "epoch 794/1000, average loss: 0.097\n",
      "6/6, loss: 0.122\n",
      "epoch 795/1000, average loss: 0.103\n",
      "6/6, loss: 0.150\n",
      "epoch 796/1000, average loss: 0.105\n",
      "6/6, loss: 0.052\n",
      "epoch 797/1000, average loss: 0.093\n",
      "6/6, loss: 0.142\n",
      "epoch 798/1000, average loss: 0.103\n",
      "6/6, loss: 0.051\n",
      "epoch 799/1000, average loss: 0.092\n",
      "6/6, loss: 0.064\n",
      "epoch 800/1000, average loss: 0.093\n",
      "6/6, loss: 0.175\n",
      "epoch 801/1000, average loss: 0.107\n",
      "6/6, loss: 0.139\n",
      "epoch 802/1000, average loss: 0.102\n",
      "6/6, loss: 0.100\n",
      "epoch 803/1000, average loss: 0.098\n",
      "6/6, loss: 0.065\n",
      "epoch 804/1000, average loss: 0.095\n",
      "6/6, loss: 0.172\n",
      "epoch 805/1000, average loss: 0.107\n",
      "6/6, loss: 0.130\n",
      "epoch 806/1000, average loss: 0.102\n",
      "6/6, loss: 0.128\n",
      "epoch 807/1000, average loss: 0.104\n",
      "6/6, loss: 0.068\n",
      "epoch 808/1000, average loss: 0.095\n",
      "6/6, loss: 0.140\n",
      "epoch 809/1000, average loss: 0.103\n",
      "6/6, loss: 0.150\n",
      "epoch 810/1000, average loss: 0.105\n",
      "6/6, loss: 0.174\n",
      "epoch 811/1000, average loss: 0.105\n",
      "6/6, loss: 0.102\n",
      "epoch 812/1000, average loss: 0.096\n",
      "6/6, loss: 0.100\n",
      "epoch 813/1000, average loss: 0.097\n",
      "6/6, loss: 0.054\n",
      "epoch 814/1000, average loss: 0.092\n",
      "6/6, loss: 0.065\n",
      "epoch 815/1000, average loss: 0.093\n",
      "6/6, loss: 0.138\n",
      "epoch 816/1000, average loss: 0.104\n",
      "6/6, loss: 0.080\n",
      "epoch 817/1000, average loss: 0.096\n",
      "6/6, loss: 0.084\n",
      "epoch 818/1000, average loss: 0.095\n",
      "6/6, loss: 0.136\n",
      "epoch 819/1000, average loss: 0.099\n",
      "6/6, loss: 0.061\n",
      "epoch 820/1000, average loss: 0.093\n",
      "6/6, loss: 0.101\n",
      "epoch 821/1000, average loss: 0.098\n",
      "6/6, loss: 0.122\n",
      "epoch 822/1000, average loss: 0.098\n",
      "6/6, loss: 0.103\n",
      "epoch 823/1000, average loss: 0.097\n",
      "6/6, loss: 0.021\n",
      "epoch 824/1000, average loss: 0.087\n",
      "6/6, loss: 0.137\n",
      "epoch 825/1000, average loss: 0.101\n",
      "6/6, loss: 0.094\n",
      "epoch 826/1000, average loss: 0.097\n",
      "6/6, loss: 0.146\n",
      "epoch 827/1000, average loss: 0.101\n",
      "6/6, loss: 0.165\n",
      "epoch 828/1000, average loss: 0.108\n",
      "6/6, loss: 0.115\n",
      "epoch 829/1000, average loss: 0.100\n",
      "6/6, loss: 0.081\n",
      "epoch 830/1000, average loss: 0.094\n",
      "6/6, loss: 0.137\n",
      "epoch 831/1000, average loss: 0.102\n",
      "6/6, loss: 0.116\n",
      "epoch 832/1000, average loss: 0.099\n",
      "6/6, loss: 0.100\n",
      "epoch 833/1000, average loss: 0.098\n",
      "6/6, loss: 0.101\n",
      "epoch 834/1000, average loss: 0.099\n",
      "6/6, loss: 0.132\n",
      "epoch 835/1000, average loss: 0.103\n",
      "6/6, loss: 0.176\n",
      "epoch 836/1000, average loss: 0.107\n",
      "6/6, loss: 0.068\n",
      "epoch 837/1000, average loss: 0.093\n",
      "6/6, loss: 0.050\n",
      "epoch 838/1000, average loss: 0.093\n",
      "6/6, loss: 0.116\n",
      "epoch 839/1000, average loss: 0.098\n",
      "6/6, loss: 0.061\n",
      "epoch 840/1000, average loss: 0.090\n",
      "6/6, loss: 0.079\n",
      "epoch 841/1000, average loss: 0.092\n",
      "6/6, loss: 0.053\n",
      "epoch 842/1000, average loss: 0.092\n",
      "6/6, loss: 0.022\n",
      "epoch 843/1000, average loss: 0.088\n",
      "6/6, loss: 0.062\n",
      "epoch 844/1000, average loss: 0.092\n",
      "6/6, loss: 0.170\n",
      "epoch 845/1000, average loss: 0.107\n",
      "6/6, loss: 0.064\n",
      "epoch 846/1000, average loss: 0.094\n",
      "6/6, loss: 0.059\n",
      "epoch 847/1000, average loss: 0.097\n",
      "6/6, loss: 0.058\n",
      "epoch 848/1000, average loss: 0.093\n",
      "6/6, loss: 0.155\n",
      "epoch 849/1000, average loss: 0.106\n",
      "6/6, loss: 0.129\n",
      "epoch 850/1000, average loss: 0.103\n",
      "6/6, loss: 0.101\n",
      "epoch 851/1000, average loss: 0.100\n",
      "6/6, loss: 0.176\n",
      "epoch 852/1000, average loss: 0.106\n",
      "6/6, loss: 0.053\n",
      "epoch 853/1000, average loss: 0.091\n",
      "6/6, loss: 0.178\n",
      "epoch 854/1000, average loss: 0.106\n",
      "6/6, loss: 0.100\n",
      "epoch 855/1000, average loss: 0.098\n",
      "6/6, loss: 0.151\n",
      "epoch 856/1000, average loss: 0.107\n",
      "6/6, loss: 0.055\n",
      "epoch 857/1000, average loss: 0.094\n",
      "6/6, loss: 0.061\n",
      "epoch 858/1000, average loss: 0.095\n",
      "6/6, loss: 0.141\n",
      "epoch 859/1000, average loss: 0.104\n",
      "6/6, loss: 0.068\n",
      "epoch 860/1000, average loss: 0.095\n",
      "6/6, loss: 0.022\n",
      "epoch 861/1000, average loss: 0.087\n",
      "6/6, loss: 0.149\n",
      "epoch 862/1000, average loss: 0.103\n",
      "6/6, loss: 0.079\n",
      "epoch 863/1000, average loss: 0.096\n",
      "6/6, loss: 0.175\n",
      "epoch 864/1000, average loss: 0.107\n",
      "6/6, loss: 0.087\n",
      "epoch 865/1000, average loss: 0.098\n",
      "6/6, loss: 0.023\n",
      "epoch 866/1000, average loss: 0.087\n",
      "6/6, loss: 0.116\n",
      "epoch 867/1000, average loss: 0.099\n",
      "6/6, loss: 0.176\n",
      "epoch 868/1000, average loss: 0.108\n",
      "6/6, loss: 0.139\n",
      "epoch 869/1000, average loss: 0.101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25544/3259558659.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25544/930139329.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25544/2523793512.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Transformer expects (seq_len, batch_size, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Back to (batch_size, seq_len, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \"\"\"\n\u001b[1;32m--> 320\u001b[1;33m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[0;32m    321\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0;32m    322\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m   1029\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m   1032\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   5080\u001b[0m     \u001b[1;31m# (deep breath) calculate attention and out projection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5081\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5082\u001b[1;33m     \u001b[0mattn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_scaled_dot_product_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5083\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5084\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_scaled_dot_product_attention\u001b[1;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[0;32m   4828\u001b[0m     \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4829\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4830\u001b[1;33m         \u001b[0mattn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4831\u001b[0m     \u001b[1;31m# (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4832\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = SequenceDataset(profiles, labels)\n",
    "dataloaer = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: (\n",
    "    torchd.nn.utils.rnn.pad_sequence([torch.tensor(p[0]) for p in x], batch_first=True),\n",
    "    torch.nn.utils.rnn.pad_sequence([torch.tensor(p[1]) for p in x], batch_first=True, padding_value=-1)\n",
    "))\n",
    "\n",
    "input_dim = np.shape(profiles[0])[-1]\n",
    "num_classes = 2\n",
    "\n",
    "#model = TransformerModel(input_dim, num_classes)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore padding in labels\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.tensor(dataset[2][0]).float()\n",
    "tmp = tmp.reshape(1, *tmp.shape)\n",
    "out = model.forward(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3889e19d0>,\n",
       " <matplotlib.lines.Line2D at 0x1a39a398c70>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tmp[0][:, 0])\n",
    "plt.plot(out[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
